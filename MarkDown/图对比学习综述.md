# 1 问题定义和相关背景

## 1.1 图定义

$$
G=\{V,E\}
$$

$$
V = \{v_1,v_2,...,v_n\}
$$

$$
E = \{e_1,e_2,...,e_m\}
$$

$$
A \in {\mathbb R^{n\times n}}
$$

属性图：节点关联着自身特征
$$
X \in {\mathbb R^{n\times d}}
$$
同质信息图：图只有一种节点类型和边类型

异质信息图：具有不止一种类型的节点或者边的图

二部图：特殊的异质信息网络，其只有两种类型的节点，并且只有不同类型的节点之间存在连边

多元图：特殊的异质信息网络，它只包含一种类型的节点，但具有多种类型的连边



## 1.2 对比学习

<img src="C:\Users\Asus\AppData\Roaming\Typora\typora-user-images\image-20231016150531579.png" alt="image-20231016150531579" style="zoom:50%;" />

1. 正负例的定义与产生方式
2. 编码模型的架构
3. 损失函数的形式



## 1.3 图神经网络

略



## 1.4 图分析下游任务

- 节点级任务：节点分类
- 边级任务：连边预测
- 图级任务：图分类



# 2 节点级图对比方法

<img src="C:\Users\Asus\AppData\Roaming\Typora\typora-user-images\image-20231016151906068.png" alt="image-20231016151906068" style="zoom:50%;" />

## 2.1 实例对比

核心思想：期望一个样本的不同增强样本之间相似并且与其他的样本不相似

**GRACE** 

<img src="C:\Users\Asus\AppData\Roaming\Typora\typora-user-images\image-20231016152538765.png" alt="image-20231016152538765" style="zoom:50%;" />

生成增强图是基于实例对比的图对比学习模型的关键组成部分，不同的增强图反映了节点不同的
上下文信息。ＧＲＡＣＥ 提出了去边的增强方法。该方法对于每条边进行一次伯努利采样，如果结果为１则这条边被保留，否则这条边被移除。然而其随机过滤连边或者特征的数据增强方式没有考虑图数据自身的特点，即没有考虑不同连边或特征的重要性

**GCA**

GCA 根据节点的重要性从真实连边集合中采样出部分连边，从而得到增强后的图。GCA 提出了利用节点重要性来自适应定义边和属性采样概率的自适应图增强方式，但是其概率值仍然是通过启发式定义的

**GCC**

图采样的方式进行数据增强

该模型的图采样包含三个步骤：

带重启的随机游走（Ｒａｎｄｏｍ ｗａｌｋ ｗｉｔｈ ｒｅｓｔａｒｔ）

子图归纳（Ｓｕｂｇｒａｐｈ ｉｎｄｕｃｔｉｏｎ）

匿名化（Ａｎｏｎｙｍｉｚａｔｉｏｎ）



## 2.2 跨级别对比

**DGI** 

<img src="C:\Users\Asus\AppData\Roaming\Typora\typora-user-images\image-20231016153627230.png" alt="image-20231016153627230" style="zoom:80%;" />

**GIC**

<img src="C:\Users\Asus\AppData\Roaming\Typora\typora-user-images\image-20231016153737573.png" alt="image-20231016153737573" style="zoom:80%;" />

节点往往属于多个集群，包括拓扑上邻近的节点形成的集群或者具有相似结构但在拓扑上彼此远离的节点形成的集群,GIC 定义类的质心表示和类中的任意一个节点表示构成正例，类的质心表示同腐化后图中相应的节点表示构成负例

**多视角图对比学习框架**

<img src="C:\Users\Asus\AppData\Roaming\Typora\typora-user-images\image-20231016154257025.png" alt="image-20231016154257025" style="zoom:80%;" />

数据增强给模型提供了多个视角去理解原始数据，从而能在很多任务上取得更好的效果

**SUBG-CON**

<img src="C:\Users\Asus\AppData\Roaming\Typora\typora-user-images\image-20231016154618372.png" alt="image-20231016154618372" style="zoom:80%;" />

# 3 边级别图对比学习

边级别的图对比学习利用图的结构信息（连边）来定义正负例，期望相邻的节点表示相似，其他节点

表示相互远离
$$
J_{\,G}(Z_{u})=-\log(\sigma(Z_{u}^{T}Z_{v}))-Q\cdot {\mathbb E}_{v_{u}\sim P_{n}(v)}\log(\sigma(-Z_{u}^{T}Z_{v_{n}}))
$$
现有的边对比学习方法的差异主要在于**编码器的设计以及对于“相邻节点”的定义**

**GAE**

<img src="C:\Users\Asus\AppData\Roaming\Typora\typora-user-images\image-20231016155519775.png" alt="image-20231016155519775" style="zoom:80%;" />

编码器采用多层ＧＣＮ得到节点表示，解码器利用点积得到任意两节点对之间的相似度，并期望有连边的节点对相似度大（正例），其他节点对相似度小（负例），ARGE 模型在 GAE 模型的基础上引入了对抗正则项，提升了模型的鲁棒性和泛化能力

**GPT-GNN**

<img src="C:\Users\Asus\AppData\Roaming\Typora\typora-user-images\image-20231016160005730.png" alt="image-20231016160005730" style="zoom:80%;" />

由于真实网络中的连边存在噪声，将所有连边视为正例可能会过拟合这些噪声，GPT-GNN 模型通过随机删去某些连边，利用剩下的图为节点学习表示，将删去的连边视为正例，将剩下的节点对视为负例进行对比

**GMI**

<img src="C:\Users\Asus\AppData\Roaming\Typora\typora-user-images\image-20231016160028821.png" alt="image-20231016160028821" style="zoom:80%;" />

GMI 模型，从特征和结构两个角度来进行对比，ＧＭＩ模型本质上是在建模两种基于边的对比学习模式，${\mathit{I}}\left(h_{i};x_{j}\right)$ 考虑基于边的特征对比，$I\left({\mathcal w}_{i j};a_{i j}\right) $ 考虑基于边的相似度对比

第一个对比任务定义正样本为目标节点的表示 $h_i$ 与其邻居节点的输入属性 $x_j$ 构成正样本，$h_i$ 与图上非邻居节点的输入属性 $x_j^{\prime}$ 构成负样本

第二个对比任务定义有边相连的节点对为正样本，没有边相连的节点对为负样本

# 4 图级别图对比学习

略

# 5 图对比学习扩展

## 5.1 不同类型的图上的扩展

**HDGI**

<img src="C:\Users\Asus\AppData\Roaming\Typora\typora-user-images\image-20231016162946149.png" alt="image-20231016162946149" style="zoom:80%;" />

HDGI 仍然将图表示和图中节点构成正样本，与腐化后图中的节点表示构成负样本

**HeCo**

<img src="C:\Users\Asus\AppData\Roaming\Typora\typora-user-images\image-20231016163107753.png" alt="image-20231016163107753" style="zoom:80%;" />

## 5.2 结合监督信息的图对比学习

略

# 6 挑战与展望

由于图数据本身就是一种抽象的数据结构，应用现有的增强操作（如增边删边，隐藏部分特征维度）后，难以直观判断原来的节点／图是否保持类别不变。因此设计增强后类别保持不变的图增强操作是未来重要的发展方向

此外如何判断哪种数据增强的方式是对于对比学习有效的，也是一个重要方向